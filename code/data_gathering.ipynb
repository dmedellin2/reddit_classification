{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering\n",
    "\n",
    "This notebook will run through the r/pandr and r/dundermifflin subreddits to gather our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from Mahdi Shadkam-Farrokhi project 3 intro lesson\n",
    "\n",
    "def query_pushshift(subreddit, kind = 'submission', day_window = 180, n = 20):\n",
    "    SUBFIELDS = ['title', 'selftext', 'subreddit', 'created_utc', 'author', 'num_comments', 'score', 'is_self']\n",
    "    \n",
    "    # establish base url and stem\n",
    "    BASE_URL = f\"https://api.pushshift.io/reddit/search/{kind}\" # also known as the \"API endpoint\" \n",
    "    stem = f\"{BASE_URL}?subreddit={subreddit}&size=500\" # always pulling max of 500\n",
    "    \n",
    "    # instantiate empty list for temp storage\n",
    "    posts = []\n",
    "    \n",
    "    # implement for loop with `time.sleep(2)`\n",
    "    for i in range(1, n + 1):\n",
    "        URL = \"{}&after={}d\".format(stem, day_window * i)\n",
    "        print(\"Querying from: \" + URL)\n",
    "        response = requests.get(URL)\n",
    "        assert response.status_code == 200\n",
    "        mine = response.json()['data']\n",
    "        df = pd.DataFrame.from_dict(mine)\n",
    "        posts.append(df)\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # pd.concat storage list\n",
    "    full = pd.concat(posts, sort=False)\n",
    "    \n",
    "    # if submission\n",
    "    if kind == \"submission\":\n",
    "        # select desired columns\n",
    "        full = full[SUBFIELDS]\n",
    "        # drop duplicates\n",
    "        full.drop_duplicates(inplace = True)\n",
    "        # select `is_self` == True\n",
    "        full = full.loc[full['is_self'] == True]\n",
    "\n",
    "    # create `timestamp` column\n",
    "    full['timestamp'] = full[\"created_utc\"].map(dt.date.fromtimestamp)\n",
    "    \n",
    "    print(\"Query Complete!\")    \n",
    "    return full "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=180d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=360d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=540d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=720d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=900d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=1080d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=1260d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=1440d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=1620d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=1800d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=1980d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=2160d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=2340d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=2520d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=2700d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=2880d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=3060d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=3240d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=3420d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=PandR&size=500&after=3600d\n",
      "Query Complete!\n"
     ]
    }
   ],
   "source": [
    "parks_df = query_pushshift('PandR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Letter to Brendanawicz</td>\n",
       "      <td>This guy had no chance. He started out being c...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571349530</td>\n",
       "      <td>RandySwango</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Just started watching the show on Amazon Prime...</td>\n",
       "      <td>At least on season two as I've noticed the sub...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571352782</td>\n",
       "      <td>Oo00oOo00oOO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Office Ladies podcast just came out to discuss...</td>\n",
       "      <td></td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571353982</td>\n",
       "      <td>ImplicationOfDanger</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Noticed they didn't mention jerry in the S3 recap</td>\n",
       "      <td>The beginning of season 3 episode 1 has a reca...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571367525</td>\n",
       "      <td>hogmanjr100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Star trek movies rule</td>\n",
       "      <td>My favorite seasons are definitely 3/5/7. Seas...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571407817</td>\n",
       "      <td>DEEP_HURTING</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "4                              Letter to Brendanawicz   \n",
       "9   Just started watching the show on Amazon Prime...   \n",
       "11  Office Ladies podcast just came out to discuss...   \n",
       "21  Noticed they didn't mention jerry in the S3 recap   \n",
       "30                              Star trek movies rule   \n",
       "\n",
       "                                             selftext subreddit  created_utc  \\\n",
       "4   This guy had no chance. He started out being c...     PandR   1571349530   \n",
       "9   At least on season two as I've noticed the sub...     PandR   1571352782   \n",
       "11                                                        PandR   1571353982   \n",
       "21  The beginning of season 3 episode 1 has a reca...     PandR   1571367525   \n",
       "30  My favorite seasons are definitely 3/5/7. Seas...     PandR   1571407817   \n",
       "\n",
       "                 author  num_comments  score  is_self   timestamp  \n",
       "4           RandySwango             4     18     True  2019-10-17  \n",
       "9          Oo00oOo00oOO             0      1     True  2019-10-17  \n",
       "11  ImplicationOfDanger             6     11     True  2019-10-17  \n",
       "21          hogmanjr100             4      6     True  2019-10-17  \n",
       "30         DEEP_HURTING             0      3     True  2019-10-18  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df.to_csv('../data/parks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=180d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=360d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=540d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=720d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=900d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=1080d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=1260d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=1440d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=1620d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=1800d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=1980d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=2160d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=2340d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=2520d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=2700d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=2880d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=3060d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=3240d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=3420d\n",
      "Querying from: https://api.pushshift.io/reddit/search/submission?subreddit=DunderMifflin&size=500&after=3600d\n",
      "Query Complete!\n"
     ]
    }
   ],
   "source": [
    "office_df = query_pushshift('DunderMifflin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2049, 9)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parks_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2626, 9)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "office_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I really wish we were able to see Michael's op...</td>\n",
       "      <td>Title says it all basically. People who've see...</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1571343765</td>\n",
       "      <td>Corndogred</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PLOT HOLE ALERT</td>\n",
       "      <td>In the segment \"Kevin cooks stuff in the offic...</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1571346137</td>\n",
       "      <td>Loyalarad2007</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Looking for a specific blooper</td>\n",
       "      <td>What season do I have to look at to find the b...</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1571347273</td>\n",
       "      <td>busterhead</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I just realized the guy at the high school job...</td>\n",
       "      <td></td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1571350005</td>\n",
       "      <td>lianagolucky</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>“I’m doing the best I can here so you can get ...</td>\n",
       "      <td>Why did that create scenes like this for Pam. ...</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1571350614</td>\n",
       "      <td>StrongHandDan</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "8   I really wish we were able to see Michael's op...   \n",
       "16                                    PLOT HOLE ALERT   \n",
       "19                     Looking for a specific blooper   \n",
       "25  I just realized the guy at the high school job...   \n",
       "29  “I’m doing the best I can here so you can get ...   \n",
       "\n",
       "                                             selftext      subreddit  \\\n",
       "8   Title says it all basically. People who've see...  DunderMifflin   \n",
       "16  In the segment \"Kevin cooks stuff in the offic...  DunderMifflin   \n",
       "19  What season do I have to look at to find the b...  DunderMifflin   \n",
       "25                                                     DunderMifflin   \n",
       "29  Why did that create scenes like this for Pam. ...  DunderMifflin   \n",
       "\n",
       "    created_utc         author  num_comments  score  is_self   timestamp  \n",
       "8    1571343765     Corndogred             3      2     True  2019-10-17  \n",
       "16   1571346137  Loyalarad2007            10      1     True  2019-10-17  \n",
       "19   1571347273     busterhead             1      1     True  2019-10-17  \n",
       "25   1571350005   lianagolucky             3      6     True  2019-10-17  \n",
       "29   1571350614  StrongHandDan            11      1     True  2019-10-17  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "office_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_df.to_csv('../data/office.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     I really wish we were able to see Michael's op...\n",
       "16                                      PLOT HOLE ALERT\n",
       "19                       Looking for a specific blooper\n",
       "25    I just realized the guy at the high school job...\n",
       "29    “I’m doing the best I can here so you can get ...\n",
       "31                            Dwight as Hannibal Lecter\n",
       "35    The scene where dwight tries to comfort pam wh...\n",
       "49                          Season 9 Andy is the worst!\n",
       "53                          I just noticed something...\n",
       "55                                 Season 9 is terrible\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "office_df['title'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.concat([parks_df, office_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.to_csv('../data/reddit.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>is_self</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Letter to Brendanawicz</td>\n",
       "      <td>This guy had no chance. He started out being c...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571349530</td>\n",
       "      <td>RandySwango</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just started watching the show on Amazon Prime...</td>\n",
       "      <td>At least on season two as I've noticed the sub...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571352782</td>\n",
       "      <td>Oo00oOo00oOO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Office Ladies podcast just came out to discuss...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571353982</td>\n",
       "      <td>ImplicationOfDanger</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noticed they didn't mention jerry in the S3 recap</td>\n",
       "      <td>The beginning of season 3 episode 1 has a reca...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571367525</td>\n",
       "      <td>hogmanjr100</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Star trek movies rule</td>\n",
       "      <td>My favorite seasons are definitely 3/5/7. Seas...</td>\n",
       "      <td>PandR</td>\n",
       "      <td>1571407817</td>\n",
       "      <td>DEEP_HURTING</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>Ultimate troll (X-post from f7u12)</td>\n",
       "      <td>Here it is:\\n\\nhttp://i.imgur.com/78ONN.jpg</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1306295681</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>Let's face it: The Office is over and peaked s...</td>\n",
       "      <td>Mine:\\n\\n1. Michael Scott\\n2. Dwight Schrute\\n...</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1306301631</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>Did anyone catch the Producer's Cut of the \"Go...</td>\n",
       "      <td>Missed the episode myself.   The internet is s...</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1306474964</td>\n",
       "      <td>notnotbuddy</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-05-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>Best Michael vs. Toby scene?</td>\n",
       "      <td>I personally love [this one](http://youtu.be/-...</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1306625629</td>\n",
       "      <td>french91</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-05-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>Toby's weight</td>\n",
       "      <td>Did anyone else notice that Toby (Paul Liebers...</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>1306714243</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>True</td>\n",
       "      <td>2011-05-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4675 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0                                Letter to Brendanawicz   \n",
       "1     Just started watching the show on Amazon Prime...   \n",
       "2     Office Ladies podcast just came out to discuss...   \n",
       "3     Noticed they didn't mention jerry in the S3 recap   \n",
       "4                                 Star trek movies rule   \n",
       "...                                                 ...   \n",
       "4670                 Ultimate troll (X-post from f7u12)   \n",
       "4671  Let's face it: The Office is over and peaked s...   \n",
       "4672  Did anyone catch the Producer's Cut of the \"Go...   \n",
       "4673                       Best Michael vs. Toby scene?   \n",
       "4674                                      Toby's weight   \n",
       "\n",
       "                                               selftext      subreddit  \\\n",
       "0     This guy had no chance. He started out being c...          PandR   \n",
       "1     At least on season two as I've noticed the sub...          PandR   \n",
       "2                                                   NaN          PandR   \n",
       "3     The beginning of season 3 episode 1 has a reca...          PandR   \n",
       "4     My favorite seasons are definitely 3/5/7. Seas...          PandR   \n",
       "...                                                 ...            ...   \n",
       "4670        Here it is:\\n\\nhttp://i.imgur.com/78ONN.jpg  DunderMifflin   \n",
       "4671  Mine:\\n\\n1. Michael Scott\\n2. Dwight Schrute\\n...  DunderMifflin   \n",
       "4672  Missed the episode myself.   The internet is s...  DunderMifflin   \n",
       "4673  I personally love [this one](http://youtu.be/-...  DunderMifflin   \n",
       "4674  Did anyone else notice that Toby (Paul Liebers...  DunderMifflin   \n",
       "\n",
       "      created_utc               author  num_comments  score  is_self  \\\n",
       "0      1571349530          RandySwango             4     18     True   \n",
       "1      1571352782         Oo00oOo00oOO             0      1     True   \n",
       "2      1571353982  ImplicationOfDanger             6     11     True   \n",
       "3      1571367525          hogmanjr100             4      6     True   \n",
       "4      1571407817         DEEP_HURTING             0      3     True   \n",
       "...           ...                  ...           ...    ...      ...   \n",
       "4670   1306295681            [deleted]             2     21     True   \n",
       "4671   1306301631            [deleted]             2      0     True   \n",
       "4672   1306474964          notnotbuddy             4     10     True   \n",
       "4673   1306625629             french91            17      9     True   \n",
       "4674   1306714243            [deleted]            14     29     True   \n",
       "\n",
       "       timestamp  \n",
       "0     2019-10-17  \n",
       "1     2019-10-17  \n",
       "2     2019-10-17  \n",
       "3     2019-10-17  \n",
       "4     2019-10-18  \n",
       "...          ...  \n",
       "4670  2011-05-24  \n",
       "4671  2011-05-25  \n",
       "4672  2011-05-27  \n",
       "4673  2011-05-28  \n",
       "4674  2011-05-29  \n",
       "\n",
       "[4675 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem statement:\n",
    "\n",
    "Mahdi's: Hacker said these two shows were so similar, it didn't matter to keep them separate -- shuffled the two subreddits but Mahdi was able to separate the two.\n",
    "\n",
    "Mine?: NBC is looking to see how people on the internet engage with some of their most famous sitcoms. They assigned an intern to gather all the posts he could on reddit for the team to analyze later on. This intern is well.. an intern, and he just put all the posts into one folder! We were able to separate most posts, but the last two shows are still stuck together.. \"The Office\" and \"Parks and Recreation.\" Given that they share some of the same creators, characterter names, and even actors (looking at you Rashida Jones..) our job is to build a model that is able to sort through these reddit posts and separate them back into their appropriate reddit threads (The Office -- r/DunderMifflin or Parks and Recreation -- r/PandR). \n",
    "\n",
    "On top of that, NBC is also interested in what content helped made it possible to differentiate between the two shows. We will build a classification model and measure our success through accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tfidf count vectorizer columns + other features (number of col) + (dummied tags?)\n",
    "- don't have to use extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
